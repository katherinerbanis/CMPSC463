Implement Prim's algorithm with heap

import heapq

def prim(graph, start_vertex):
# Priority Queue: (weight, (vertex1, vertex2))
pq = []
visited = set()
mst_edges = []

# Helper function to add edges to the priority queue
def add_edges(vertex):
visited.add(vertex)
for neighbor, weight in graph[vertex]:
if neighbor not in visited:
heapq.heappush(pq, (weight, (vertex, neighbor)))

# Start from the initial vertex
add_edges(start_vertex)

while pq:
weight, (vertex1, vertex2) = heapq.heappop(pq)
if vertex2 not in visited:
mst_edges.append((vertex1, vertex2, weight))
add_edges(vertex2)

return mst_edges

# Example usage
graph = {
0: [(1, 1), (2, 4)],
1: [(0, 1), (2, 2), (3, 5)],
2: [(0, 4), (1, 2), (3, 1)],
3: [(1, 5), (2, 1)],
}

mst = prim(graph, 0)
print("Minimum Spanning Tree:", mst)

Explanation:
The graph is represented as an adjacency list where each key is a vertex and its value is a list of tuples that contain the adjacent vertices and the weight of the edge joining them.
Python's heapq was used to implement a min heap. This gives us the edge with the minimum weight efficiently.
The add_edges function adds all of the edges of a newly visited vertex into the priority queue.

Toy Example:
Input:
graph = {

    0: [(1, 1), (2, 4)],

    1: [(0, 1), (2, 2), (3, 5)],

    2: [(0, 4), (1, 2), (3, 1)],

    3: [(1, 5), (2, 1)],

}

Start vertex: 0

Output: Minimum Spanning Tree: [(0, 1, 1), (1, 2, 2), (2, 3, 1)]

Discuss Output:

The algorithm begins at vertex 0, adding the edge (0, 1, 1) to the MST. Then it adds edge (1, 2, 2) to the MST. Then is adds (2, 3, 1), which connects the MST to the last vertex. This is correct because it connects all vertices with the smallest possible sum. 1 + 2 + 1 = 4

 

Implement Clustering Algorithm

class UnionFind:
def __init__(self, n):
self.parent = list(range(n))
self.rank = [0] * n
def find(self, u):
if self.parent[u] != u:
self.parent[u] = self.find(self.parent[u]) # Path compression
return self.parent[u]
def union(self, u, v):
root_u = self.find(u)
root_v = self.find(v)
if root_u != root_v:
# Union by rank
if self.rank[root_u] > self.rank[root_v]:
self.parent[root_v] = root_u
elif self.rank[root_u] < self.rank[root_v]:
self.parent[root_u] = root_v
else:
self.parent[root_v] = root_u
self.rank[root_u] += 1
return True
return False

def kruskal_clustering(graph, n, k):
edges = []
for u in graph:
for v, weight in graph[u]:
edges.append((weight, u, v))
edges.sort() # Sort edges by weight
uf = UnionFind(n)
mst_edges = []
clusters = n # Initially, each node is its own cluster

for weight, u, v in edges:
if uf.union(u, v):
mst_edges.append((u, v, weight))
clusters -= 1
if clusters == k: # Stop once we have 'k' clusters
break
# Return the clusters formed by the union-find parent array
cluster_dict = {}
for i in range(n):
root = uf.find(i)
if root not in cluster_dict:
cluster_dict[root] = []
cluster_dict[root].append(i)
return cluster_dict, mst_edges

# Example usage
graph = {
0: [(1, 1), (2, 4)],
1: [(0, 1), (2, 2), (3, 5)],
2: [(0, 4), (1, 2), (3, 1)],
3: [(1, 5), (2, 1)],
}

n = 4 # Number of vertices
k = 2 # Desired number of clusters
clusters, mst_edges = kruskal_clustering(graph, n, k)

print("Clusters:", clusters)
print("Edges in MST:", mst_edges)
Explanation:
Kruskal's algorithm sorts all edges by weight. Union-Find is used to avoid cycles while adding edges. Clustering was modified so that instead of building a single connected component, the process is stopped when we have the desired number of clusters.
Toy Example:
Input:
graph = {

    0: [(1, 1), (2, 4)],

    1: [(0, 1), (2, 2), (3, 5)],

    2: [(0, 4), (1, 2), (3, 1)],

    3: [(1, 5), (2, 1)],

}

n = 4  # Number of vertices

k = 2  # Desired number of clusters

Output: 

Clusters: {0: [0, 1], 2: [2, 3]}
Edges in MST: [(0, 1, 1), (1, 2, 2), (2, 3, 1)]
